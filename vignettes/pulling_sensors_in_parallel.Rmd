---
title: "Pull multiple sensors using parallel processing"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Pull multiple sensors using parallel processing}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

## Pull data for select sensors for all 2019  

```{r, eval = FALSE}
library(tc.sensors)
library(doParallel)
library(foreach)
library(dplyr)
library(magrittr)
library(tictoc) # If you want to benchmark - but you shouldn't have to; I already did (:

sensor_config <- pull_configuration()
sensor_ids <- pull_sensor_ids()

cores <- detectCores()
cl <- makeCluster(cores)
registerDoParallel(cl)
tic() # Start the timer

foreach(j = sensor_ids[[1]][633:714]) %dopar% {
  date_range <- seq(as.Date("2019/01/01"), as.Date("2019/12/31"), by = "days")
  n <- length(date_range)
  loops_ls <- vector("list", n)
  
  for (i in 1:n) {
    loops_ls[[i]] <- tc.sensors::pull_sensor(j, date_range[[i]])
  }
  
  loops_df <- data.table::rbindlist(loops_ls)
  data.table::fwrite(loops_df, paste0("../../MnDOT_Loop_Detectors/Volume-Occupancy/2019/Sensor ", j, ".csv"))
}
toc()
stopCluster(cl)

```

## Save to Microsoft Access Database  

```{r, eval=FALSE}
library(RODBC)

test_conn <- odbcConnectAccess2007("../LoopDBTest.accdb")
sqlTables(test_conn, tableType = "TABLE")$TABLE_NAME # Check available tables

sqlSave(channel = test_conn,
        dat = loops_df,
        append = T,
        tablename = "testtable",
        rownames = F) # Prevents RStudio from crashing

check <- RODBC::sqlQuery(test_conn, "SELECT * from testtable WHERE date = 20191231")

```
